{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Setup environment"
      ],
      "metadata": {
        "id": "zhXPS75JocTJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlI04lSCl3T9"
      },
      "outputs": [],
      "source": [
        "!pip install llama-cpp-python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download model. For this example, we are using CodeLLAMA 13B Instruct."
      ],
      "metadata": {
        "id": "hdyUWuUfoak5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q6_K.gguf"
      ],
      "metadata": {
        "id": "KbEFtrCynIHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If you already have the model downloaded, or want to save it run the following sections."
      ],
      "metadata": {
        "id": "2mBPCE6glSyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enable Drive Connection by Clicking the Button at Files at tab."
      ],
      "metadata": {
        "id": "wRdKk3zvldmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Model to Drive"
      ],
      "metadata": {
        "id": "N8IbZ9KGlaeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./mistral-7b-instruct-v0.2.Q6_K.gguf \"/content/drive/MyDrive/LLAMA Models/\""
      ],
      "metadata": {
        "id": "_NG-6VpOlSel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Model from Drive"
      ],
      "metadata": {
        "id": "YIQDqEIxlrwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/LLAMA Models/mistral-7b-instruct-v0.2.Q6_K.gguf\" ./mistral-7b-instruct-v0.2.Q6_K.gguf"
      ],
      "metadata": {
        "id": "tgTz1PDnlrht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translator functions"
      ],
      "metadata": {
        "id": "EZRttQy0pzt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama, LlamaGrammar\n",
        "llm = Llama(model_path=\"./mistral-7b-instruct-v0.2.Q6_K.gguf\", n_ctx=2048, use_mlock=True)"
      ],
      "metadata": {
        "id": "r0UqTZeeqVz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "def infer_translator(text):\n",
        "\n",
        "    logging.info(\"Translating text: \" + text)\n",
        "\n",
        "    prompt = f'''[INST]<<SYS>>You are a professional translator.\n",
        "You will first transliterate the Chinese sentences into Latin alphabet.\n",
        "Then, you will translate the given Chinese sentences into English.\n",
        "For example:\n",
        "Chinese: 你好\n",
        "Transliteration: nihao\n",
        "English: Hello\n",
        "[END]<</SYS>>\n",
        "\n",
        "Here is the first sentence:\n",
        "Chinese: {text}\n",
        "Transliteration:[/INST]'''\n",
        "\n",
        "    grammar_string = r'''# root rule defining the overall format of the answer\n",
        "root ::= answer\n",
        "\n",
        "# rule for the answer section\n",
        "answer ::= transliteration \"English: \" english-text\n",
        "\n",
        "# rule for the transliteration section\n",
        "transliteration ::= \"Transliteration: \" trans-text \"\\n\"\n",
        "\n",
        "# rule for the English translation section\n",
        "english-text ::= [^\\n]+ \"\\n\"\n",
        "\n",
        "# rule to match any sequence of characters for the transliteration, excluding newline\n",
        "trans-text ::= [^\\n]+ \"\\n\"\n",
        "\n",
        "# Note: [^\\n] denotes any character except a newline, and + indicates one or more repetitions.\n",
        "'''\n",
        "    grammar = LlamaGrammar.from_string(grammar_string)\n",
        "    temperature = 0.2\n",
        "    top_k = 40\n",
        "    top_p = 0.9\n",
        "    max_tokens = 256\n",
        "    stop = [\"[END]\"]\n",
        "\n",
        "    # response = llm(prompt=prompt, grammar=grammar, temperature=temperature, top_k=top_k, top_p=top_p, max_tokens=max_tokens, stop=stop)\n",
        "\n",
        "    # response_content = response[\"choices\"][0][\"text\"]\n",
        "\n",
        "    # logging.info(response_content)\n",
        "\n",
        "    response_iterator = llm(prompt=prompt, grammar=grammar, temperature=temperature, top_k=top_k, top_p=top_p, max_tokens=max_tokens, stop=stop, stream=True)\n",
        "\n",
        "    return response_iterator"
      ],
      "metadata": {
        "id": "_bw4ZWjpohc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer_translator(\"你好\")"
      ],
      "metadata": {
        "id": "kMlp5Tg3tbbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import time\n",
        "\n",
        "# Text widget for input\n",
        "input_text = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Text to translate',\n",
        "    description='Input:',\n",
        "    disabled=False,\n",
        "    layout={'height': '100px', 'width': '600px'}\n",
        ")\n",
        "\n",
        "# Button to execute function\n",
        "execute_button = widgets.Button(description=\"Translate\")\n",
        "\n",
        "progress_bar = widgets.IntProgress(\n",
        "    value=0,\n",
        "    min=0,\n",
        "    max=100,\n",
        "    description='Progress:',\n",
        "    bar_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    orientation='horizontal'\n",
        ")\n",
        "\n",
        "\n",
        "# Textarea widgets to display the results\n",
        "output1 = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Transliteration will be displayed here',\n",
        "    description='Transliteration:',\n",
        "    disabled=True,\n",
        "    layout={'height': '200px', 'width': '600px'}  # Adjust height and width as needed\n",
        ")\n",
        "\n",
        "output2 = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Translation will be displayed here',\n",
        "    description='Translation:',\n",
        "    disabled=True,\n",
        "    layout={'height': '200px', 'width': '600px'}  # Adjust height and width as needed\n",
        ")\n",
        "\n",
        "# Function to be executed\n",
        "def execute_function(change):\n",
        "    progress_bar.value = 0\n",
        "    progress_bar.max = 3  # Set this to a high number for a smooth progress bar\n",
        "    progress_bar.style.bar_color = 'blue'\n",
        "    display(progress_bar)\n",
        "\n",
        "    # Step 1: You might want to update progress bar here\n",
        "    progress_bar.value += 1\n",
        "\n",
        "    # output_text = infer_translator(input_text.value)\n",
        "\n",
        "    for completion in infer_translator(input_text.value):\n",
        "      completion_token = completion[\"choices\"][0][\"text\"]\n",
        "      output1.value += completion_token\n",
        "\n",
        "    output_text = output1.value\n",
        "\n",
        "    # Step 2: Another update to the progress bar\n",
        "    progress_bar.value += 1\n",
        "\n",
        "    parts = output_text.split('\\n\\n')\n",
        "    transliteration_string = parts[0] if len(parts) > 0 else \"\"\n",
        "    transliteration = transliteration_string.split('Transliteration:')[1]\n",
        "\n",
        "    translation_string = parts[1] if len(parts) > 1 else \"\"\n",
        "    translation = translation_string.split('English:')[1]\n",
        "\n",
        "    output1.value = transliteration\n",
        "    output2.value = translation\n",
        "\n",
        "    # Step 3: Final update to the progress bar\n",
        "    progress_bar.value += 1\n",
        "    progress_bar.bar_style = 'success'\n",
        "\n",
        "# Attach the function to the button\n",
        "execute_button.on_click(execute_function)\n",
        "\n",
        "# Display widgets\n",
        "display(input_text, execute_button, output1, output2)\n"
      ],
      "metadata": {
        "id": "no1IPyzyte0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example\n",
        "\n",
        "https://shanghai.nyu.edu/news/nyu-shanghai-welcomes-class-2027\n",
        "\n",
        "https://shanghai.nyu.edu/cn/news/nyu-shanghai-welcomes-class-2027\n",
        "\n",
        "On the morning of August 21, NYU Shanghai welcomed more than 400 Chinese and international students from the Class of 2027 to the school’s eleventh University Welcome, the first to be held at its newly opened New Bund Campus. While students arrived on campus on August 20 for Move-In Day, the ceremony marked the first time the students joined together as an entire class.\n",
        "\n",
        "2023年8月21日上午，上海纽约大学前滩校园热闹非凡，迎来了2023级本科生开学典礼。来自全球各地的400多名中外新生，在完成前一天的报到后，首次齐聚校园，正式开启了他们的大学之旅。"
      ],
      "metadata": {
        "id": "OuQWaOrm1YWN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sws0aNy_yYdk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}